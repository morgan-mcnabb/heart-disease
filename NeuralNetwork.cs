using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Threading.Tasks;

namespace HeartDisease
{
    class NeuralNetwork
    {
        private readonly double LearningRate;
        public Matrix InputWeights,
                        HiddenWeights,
                        BiasWeights;
        private double Bias = 1;

        public NeuralNetwork(double learningRate, int numInput, int numHidden, int numOutput)
        {
            LearningRate = learningRate;
            InputWeights = new Matrix(numHidden, numInput);
            HiddenWeights = new Matrix(numOutput, numHidden);
            // BiasWeights = new Matrix(1, numHidden + numOutput);
        }

        
        //activation function for hidden layer(s)
        //if the incoming value is greater than 0, push input forward
        //if the incoming value is less than 0, push 0 forward
        //better for large amounts of data
        //prediction: worst for predicting heart disease
        public double Relu(double input)
        {
            if (input > 0)
            {
                return input;
            }
            return 0;
        }

        //activation function for hidden layer(s)
        //sigmoid functon for producing a value between 0 and 1
        //likely better for this size of data
        //also better because range is between 0 and 1, good for percentage
        //prediction: best for predicting heart disease
        public double Sigmoid(double input)
        {
            return Math.Pow(Math.E, input) /
                  (Math.Pow(Math.E, input) + 1);
        }

        //activation function for hidden layer(s)
        //tanh function for producing a value between -1 and 1
        //very similar to sigmoid
        //input at zero equals zero, unlike sigmoid
        //prediction: won't be very good for predicting heart disease
        public double Tanh(double input)
        {
            return (Math.Pow(Math.E, 2 * input) - 1) /
                   (Math.Pow(Math.E, 2 * input) + 1);
        }


        //trains the neural network using Relu as activation
        public void TrainRelu(List<double[]> data, List<double> answer)
        {
            //iterates through entire lis of data
            for (int a = 0; a < data.Count; a++)
            {
                //handles the output generated by input multiplied by
                //their respective weights
                double[] inputOutput = { 0, 0 };

                //handles the output generated by the hidden layers
                double hiddenOutput = 0;

                //holds value for the error
                double error = 0;

                //goes through each of the weights attached to input nods
                for (int i = 0; i < InputWeights.Rows; i++)
                {
                    for (int j = 0; j < InputWeights.Columns; j++)
                    {
                        //calculates output for the input nodes
                        inputOutput[i] += data[a][j] * InputWeights.m[i, j];
                    }

                    //adds the bias to the output generated by input nodes
                    inputOutput[i] += Bias;

                    //throws the output generated from input nodes into activation
                    //function
                    inputOutput[i] += Relu(inputOutput[i]);
                }

                //goes through each of the weights attaches to hidden layer
                for (int m = 0; m < HiddenWeights.Rows; m++)
                {
                    for (int n = 0; n < HiddenWeights.Columns; n++)
                    {
                        //calculates output by the hidden layer
                        hiddenOutput += inputOutput[n] * HiddenWeights.m[m, n];
                    }

                    //adds the bias to the output
                    hiddenOutput += Bias;
                }

                //calculates the error
                error = answer[a] - hiddenOutput;

                //backpropagation
                for (int d = 0; d < HiddenWeights.Rows; d++)
                {
                    for (int e = 0; e < HiddenWeights.Columns; e++)
                    {
                        HiddenWeights.m[d, e] += inputOutput[e] * LearningRate * error;
                    }
                }

                //backpropagation
                for (int f = 0; f < InputWeights.Rows; f++)
                {
                    for (int g = 0; g < InputWeights.Columns; g++)
                    {
                        InputWeights.m[f, g] += data[a][g] * LearningRate * error;
                    }
                }
            }
        }

        public void TrainSigmoid(List<double[]> data, List<double> answer)
        {
            //iterates through entire lis of data
            for (int a = 0; a < data.Count; a++)
            {
                //handles the output generated by input multiplied by
                //their respective weights
                double[] inputOutput = { 0, 0 };

                //handles the output generated by the hidden layers
                double hiddenOutput = 0;

                //holds value for the error
                double error = 0;

                //goes through each of the weights attached to input nods
                for (int i = 0; i < InputWeights.Rows; i++)
                {
                    for (int j = 0; j < InputWeights.Columns; j++)
                    {
                        //calculates output for the input nodes
                        inputOutput[i] += data[a][j] * InputWeights.m[i, j];
                    }

                    //adds the bias to the output generated by input nodes
                    inputOutput[i] += Bias;

                    //throws the output generated from input nodes into activation
                    //function
                    inputOutput[i] += Sigmoid(inputOutput[i]);
                }

                //goes through each of the weights attaches to hidden layer
                for (int m = 0; m < HiddenWeights.Rows; m++)
                {
                    for (int n = 0; n < HiddenWeights.Columns; n++)
                    {
                        //calculates output by the hidden layer
                        hiddenOutput += inputOutput[n] * HiddenWeights.m[m, n];
                    }

                    //adds the bias to the output
                    hiddenOutput += Bias;
                }

                //calculates the error
                error = answer[a] - hiddenOutput;
                //backpropagation
                for (int d = 0; d < HiddenWeights.Rows; d++)
                {
                    for (int e = 0; e < HiddenWeights.Columns; e++)
                    {
                        HiddenWeights.m[d, e] += inputOutput[e] * LearningRate * error;
                    }
                }

                //backpropagation
                for (int f = 0; f < InputWeights.Rows; f++)
                {
                    for (int g = 0; g < InputWeights.Columns; g++)
                    {
                        InputWeights.m[f, g] += data[a][g] * LearningRate * error;
                    }
                }
            }
        }

        public void TrainTanh(List<double[]> data, List<double> answer)
        {
            //iterates through entire lis of data
            for (int a = 0; a < data.Count; a++)
            {
                //handles the output generated by input multiplied by
                //their respective weights
                double[] inputOutput = { 0, 0 };

                //handles the output generated by the hidden layers
                double hiddenOutput = 0;

                //holds value for the error
                double error = 0;

                //goes through each of the weights attached to input nods
                for (int i = 0; i < InputWeights.Rows; i++)
                {
                    for (int j = 0; j < InputWeights.Columns; j++)
                    {
                        //calculates output for the input nodes
                        inputOutput[i] += data[a][j] * InputWeights.m[i, j];
                    }

                    //adds the bias to the output generated by input nodes
                    inputOutput[i] += Bias;

                    //throws the output generated from input nodes into activation
                    //function
                    inputOutput[i] += Tanh(inputOutput[i]);
                }

                //goes through each of the weights attaches to hidden layer
                for (int m = 0; m < HiddenWeights.Rows; m++)
                {
                    for (int n = 0; n < HiddenWeights.Columns; n++)
                    {
                        //calculates output by the hidden layer
                        hiddenOutput += inputOutput[n] * HiddenWeights.m[m, n];
                    }

                    //adds the bias to the output
                    hiddenOutput += Bias;
                }

                //calculates the error
                error = answer[a] - hiddenOutput;

                //backpropagation
                for (int d = 0; d < HiddenWeights.Rows; d++)
                {
                    for (int e = 0; e < HiddenWeights.Columns; e++)
                    {
                        HiddenWeights.m[d, e] += inputOutput[e] * LearningRate * error;
                    }
                }

                //backpropagation
                for (int f = 0; f < InputWeights.Rows; f++)
                {
                    for (int g = 0; g < InputWeights.Columns; g++)
                    {
                        InputWeights.m[f, g] += data[a][g] * LearningRate * error;
                    }
                }
            }
        }

        public double Test(double[] data)
        {

            double[] inputOutput = { 0, 0 };
            double hiddenOutput = 0;
            for (int i = 0; i < InputWeights.Rows; i++)
            {
                for (int j = 0; j < InputWeights.Columns; j++)
                {
                    inputOutput[i] += data[j] * InputWeights.m[i, j];
                }
                inputOutput[i] += Bias;
                inputOutput[i] += Tanh(inputOutput[i]);
            }
            for (int m = 0; m < HiddenWeights.Rows; m++)
            {
                for (int n = 0; n < HiddenWeights.Columns; n++)
                {
                    hiddenOutput += inputOutput[n] * HiddenWeights.m[m, n];
                }
                hiddenOutput += Bias;
            }
            if(hiddenOutput >= 1)
            {
                return 1;
            }
            else if(hiddenOutput <= 0)
            {
                return 0;
            }
            return hiddenOutput;

        }
    }
}

